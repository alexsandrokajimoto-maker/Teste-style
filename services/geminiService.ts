
import { GoogleGenAI, Modality } from '@google/genai';
import { BodyPartCategory, Product } from '../types';

// Fix: Removed duplicate global type declaration for window.aistudio, which is now centralized in types.ts.


const getApiKey = (): string => {
    const key = process.env.API_KEY;
    if (!key) {
        throw new Error("API_KEY environment variable not set");
    }
    return key;
};

const fileToGenerativePart = async (file: File) => {
    const base64EncodedData = await new Promise<string>((resolve) => {
        const reader = new FileReader();
        reader.onloadend = () => resolve((reader.result as string).split(',')[1]);
        reader.readAsDataURL(file);
    });

    return {
        inlineData: {
            data: base64EncodedData,
            mimeType: file.type,
        },
    };
};

const dataUrlToBase64 = (dataUrl: string) => {
    return dataUrl.split(',')[1];
}

export const generateStyledImage = async (
    modelImage: string,
    products: Partial<Record<BodyPartCategory, Product>>
): Promise<string> => {
    const ai = new GoogleGenAI({ apiKey: getApiKey() });
    
    const modelImagePart = {
        inlineData: {
            mimeType: 'image/jpeg',
            data: dataUrlToBase64(modelImage)
        }
    };

    let promptParts: any[] = [
        modelImagePart,
        { text: "You are an expert virtual stylist. Your task is to realistically place the following clothing and accessory items onto the person in the first image. Maintain the person's original pose, proportions, and the background. Ensure the items blend naturally with the lighting and shadows of the original photo. Here are the items and where they should be placed:" }
    ];

    for (const [category, product] of Object.entries(products)) {
        if (product) {
            const productPart = await fileToGenerativePart(product.file);
            promptParts.push(productPart);
            promptParts.push({ text: `Place this item on the person's ${category.toLowerCase()}.` });
        }
    }
    
    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash-image',
        contents: {
            parts: promptParts,
        },
        config: {
            responseModalities: [Modality.IMAGE],
        },
    });

    const firstPart = response.candidates?.[0]?.content?.parts?.[0];
    if (firstPart && 'inlineData' in firstPart && firstPart.inlineData) {
        return firstPart.inlineData.data;
    }

    throw new Error("No image was generated by the API.");
};


const VIDEO_STATUS_MESSAGES = [
    "Initializing video synthesis...",
    "Warming up the digital runway...",
    "Analyzing style composition...",
    "Generating photorealistic frames...",
    "Stitching scenes together...",
    "Applying final lighting effects...",
    "Rendering high-definition video...",
    "Almost ready for the premiere...",
];

export const generateOutfitVideo = async (
    styledImage: string,
    onStatusUpdate: (status: string) => void,
    onComplete: (videoUrl: string) => void,
    onError: (error: Error) => void
) => {
    try {
        const ai = new GoogleGenAI({ apiKey: getApiKey() });
        let operation = await ai.models.generateVideos({
            model: 'veo-3.1-fast-generate-preview',
            prompt: 'Create a short, realistic video of this person making a subtle movement, like a slight turn or a gentle sway, to model the outfit. The background should remain consistent.',
            image: {
                imageBytes: dataUrlToBase64(styledImage),
                mimeType: 'image/png',
            },
            config: {
                numberOfVideos: 1,
                resolution: '720p',
                aspectRatio: '9:16',
            }
        });

        let statusIndex = 0;
        onStatusUpdate(VIDEO_STATUS_MESSAGES[statusIndex]);

        while (!operation.done) {
            await new Promise(resolve => setTimeout(resolve, 10000)); // Poll every 10 seconds
            statusIndex = (statusIndex + 1) % VIDEO_STATUS_MESSAGES.length;
            onStatusUpdate(VIDEO_STATUS_MESSAGES[statusIndex]);
            operation = await ai.operations.getVideosOperation({ operation: operation });
        }
        
        onStatusUpdate("Video generated! Fetching data...");

        const downloadLink = operation.response?.generatedVideos?.[0]?.video?.uri;
        if (downloadLink) {
            const videoResponse = await fetch(`${downloadLink}&key=${getApiKey()}`);
            if (!videoResponse.ok) {
                throw new Error(`Failed to download video: ${videoResponse.statusText}`);
            }
            const videoBlob = await videoResponse.blob();
            const videoUrl = URL.createObjectURL(videoBlob);
            onComplete(videoUrl);
        } else {
            throw new Error("Video generation completed, but no download link was provided.");
        }
    } catch (err: any) {
        onError(err);
    }
};